# This File contains the main functions used in 'Adaptive Design Optimization for a Mnemonic Similarity Task'
#### Normal approximation non-cnotaminant model ####
p_entropy <- function(responses,stimulus){
    # This function expands the current data and stimulus taken as input by adding 
    # 14 new responses, a 0 and 1 for each type of stimulus. The expanded data matrix 
    # is used to approximate the posterior distribution conditional on the response using
    # the non-contaminant model.
  library(R2jags)
  y <- responses
  x <- stimulus
  new.obs <- c(NA,rep(c(0,1),7))
  y.expanded <- t(cbind(matrix(rep(y,15),nrow=15,ncol=length(y),byrow = T),new.obs))
  new.stim <- c(NA,rep(seq(1,7),each=2))
  st.expanded <- t(cbind(matrix(rep(x,15),nrow=15,ncol=length(x),byrow = T),new.stim))
  data <- list(y = y.expanded, stimulus=st.expanded,
               trials=dim(y.expanded)[1],part=dim(y.expanded)[2],
               R=0.1*diag(6))
  parameters <- c('d','k','y.ppd')
  samples <- jags.parallel(data, parameters.to.save = parameters,
                           model.file ='models/noncontaminant.txt', 
                           n.chains=4, n.iter=10000,
                           n.burnin=5000, n.thin=1, DIC=T)
  return(samples)
}

posterior.distribution <- function(responses,stimulus,prediction = FALSE){
    # This function takes the responses and stimulus for a single participant and 
    # then analizes the sequence using sdt for a single participant, by default 
    # predictions are not drawn but if needed it can draw the posterior distribution
    # of the probability of a 'yes' response for each trial.
  library(R2jags)
  y <- responses
  x <- stimulus
  data <- list(y = y, stimulus=x,trials=length(y),part=length(y),R=1*diag(6))
  if(prediction){
    parameters <- c('d','k','theta')  
  }
  else{
    parameters <- c('d','k')
  }
  samples <- jags.parallel(data, parameters.to.save = parameters,
                           model.file ='models/noncontaminant_individual_pred.txt', 
                           n.chains=4, n.iter=10000,
                           n.burnin=5000, n.thin=1, DIC=T)
  return(samples)
}

kl_sdt <- function(rs,st){
    # This function obtains the KL divergence between the posterior distirbution using the data
    # in rs and the posterior distribution of the hypothetical participants generated by the 
    # p_entropy function. The values in output$div represent the expected KL for presenting each stimulus.
  posterior <- p_entropy(responses = rs, stimulus = st)
  ind <- rbind(cbind(seq(2,14,2),seq(3,15,2)))
  KL <- c()
  p <- posterior$BUGSoutput$mean$y.ppd
  prior.mean <- c(posterior$BUGSoutput$mean$k[1],posterior$BUGSoutput$mean$d[1,-1])
  prior.variance <- matrix(c((posterior$BUGSoutput$sd$k[1])^2,rep(0,48)),ncol=7)
  temp.variance <- array(NA,dim=c(6,6,length(posterior$BUGSoutput$sims.list$d[,1,1])))
  for(i in 1:dim(temp.variance)[3]){
    temp.variance[1:6,1:6,i] <- (posterior$BUGSoutput$sims.list$d[i,1,-1]-posterior$BUGSoutput$mean$d[1,-1])%*%
      t(posterior$BUGSoutput$sims.list$d[i,1,-1]-posterior$BUGSoutput$mean$d[1,-1])
  }
  temp.variance.2 <- matrix(NA,nrow=6,ncol=6)
  for(i in 1:6){
    for(j in 1:6){
      temp.variance.2[i,j] <- (1/dim(temp.variance)[3])*sum(temp.variance[i,j,])
    }
  }
  prior.variance[2:7,2:7] <- temp.variance.2
  for(i in 1:7){
    post.mean <- c(posterior$BUGSoutput$mean$k[ind[i,1]],posterior$BUGSoutput$mean$d[ind[i,1],-1])
    post.variance <- matrix(c((posterior$BUGSoutput$sd$k[ind[i,1]])^2,rep(0,48)),ncol=7)
    temp.variance <- array(NA,dim=c(6,6,length(posterior$BUGSoutput$sims.list$d[,1,1])))
    for(k in 1:dim(temp.variance)[3]){
      temp.variance[1:6,1:6,k] <- (posterior$BUGSoutput$sims.list$d[k,ind[i,1],-1]-posterior$BUGSoutput$mean$d[ind[i,1],-1])%*%
        t(posterior$BUGSoutput$sims.list$d[k,ind[i,1],-1]-posterior$BUGSoutput$mean$d[ind[i,1],-1])
    }
    temp.variance.2 <- matrix(NA,nrow=6,ncol=6)
    for(k in 1:6){
      for(j in 1:6){
        temp.variance.2[k,j] <- (1/dim(temp.variance)[3])*sum(temp.variance[k,j,])
      }
    }
    post.variance[2:7,2:7] <- temp.variance.2
    kl.trial0 <- klmnorm(post.mu = post.mean,
                         post.sigma = post.variance,
                         prior.mu = prior.mean,
                         prior.sigma = prior.variance)
    post.mean <- c(posterior$BUGSoutput$mean$k[ind[i,2]],posterior$BUGSoutput$mean$d[ind[i,2],-1])
    post.variance <- matrix(c(posterior$BUGSoutput$sd$k[ind[i,2]]^2,rep(0,48)),ncol=7)
    temp.variance <- array(NA,dim=c(6,6,length(posterior$BUGSoutput$sims.list$d[,1,1])))
    for(k in 1:dim(temp.variance)[3]){
      temp.variance[1:6,1:6,k] <- (posterior$BUGSoutput$sims.list$d[k,ind[i,2],-1]-posterior$BUGSoutput$mean$d[ind[i,2],-1])%*%
        t(posterior$BUGSoutput$sims.list$d[k,ind[i,2],-1]-posterior$BUGSoutput$mean$d[ind[i,2],-1])
    }
    temp.variance.2 <- matrix(NA,nrow=6,ncol=6)
    for(k in 1:6){
      for(j in 1:6){
        temp.variance.2[k,j] <- (1/dim(temp.variance)[3])*sum(temp.variance[k,j,])
      }
    }
    post.variance[2:7,2:7] <- temp.variance.2
    kl.trial1 <- klmnorm(post.mu = post.mean,
                         post.sigma = post.variance,
                         prior.mu = prior.mean,
                         prior.sigma = prior.variance)
    KL[i] <- ((1-p[i])*kl.trial0)+(p[i]*kl.trial1)
  }
  output <- list()
  output$div <- KL
  output$posterior$mu <- prior.mean
  output$posterior$sigma <- prior.variance
  output$posterior$ci <- rbind(quantile(posterior$BUGSoutput$sims.list$k[,1],probs=c(0.025,0.975,0.005,0.995,0.05,0.95)),
                                t(apply(posterior$BUGSoutput$sims.list$d[,1,],2,quantile,probs=c(0.025,0.975,0.005,0.995,0.05,0.95))))
  output$posterior$ci <- output$posterior$ci[-2,]
  return(output)
}
